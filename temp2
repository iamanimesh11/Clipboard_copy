
PySpark Revision Topics

1Ô∏è‚É£ PySpark Basics

SparkSession creation and usage

Reading/Writing data (CSV, JSON, Parquet, Hive tables)

DataFrame vs RDD (when to use which)

Schema inspection: .printSchema(), .dtypes, .schema


2Ô∏è‚É£ DataFrame Operations

Selecting columns: .select(), .withColumn()

Filtering: .filter(), .where()

Adding/modifying columns

Dropping columns: .drop()

Renaming columns: .withColumnRenamed()


3Ô∏è‚É£ Joins

Inner, left, right, full outer joins

Self-joins and multi-table joins

Broadcast joins (broadcast(df)) for small tables


4Ô∏è‚É£ Aggregations

groupBy() + agg()

Common aggregations: sum(), count(), avg(), min(), max()

Multiple aggregations at once

distinct() and dropDuplicates()


5Ô∏è‚É£ Window Functions

row_number(), rank(), dense_rank()

lead(), lag()

Partitioning and ordering in windows

Deduplication using window functions


6Ô∏è‚É£ Transformations vs Actions

Transformations: map(), flatMap(), filter(), select(), groupBy()

Actions: show(), count(), collect(), take()


7Ô∏è‚É£ Handling Nulls and Missing Data

fillna(), dropna(), replace()


8Ô∏è‚É£ Data Cleaning & Transformation

withColumn() + when/otherwise

split(), concat(), regexp_replace(), substring()

Date & timestamp manipulation


9Ô∏è‚É£ Optimization

Caching & persistence: .cache(), .persist()

Repartitioning vs coalescing: .repartition(), .coalesce()

Avoiding shuffles in joins and aggregations

Broadcast join for small tables


üîü User Defined Functions (UDFs)

Writing Python/Scala UDFs

Applying UDFs on DataFrames

Using pandas_udf for better performance


1Ô∏è‚É£1Ô∏è‚É£ Miscellaneous / Good to Review

Sorting: .orderBy(), .sort()

Collecting top-k results: .take(n), .head(n)

Joining multiple DataFrames efficiently

Using .alias() for column names

Basic Spark SQL queries: spark.sql("SELECT ...")



