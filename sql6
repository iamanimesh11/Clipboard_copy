ğŸ”¥ Yesss you nailed that one! Now letâ€™s move into a data quality + audit-style SQL challenge â€” the kind often used in data engineering interviews and real-world pipeline checks.


---

ğŸ§  Business Case: Find Duplicate Orders in System

> You're on the data team for an e-commerce company. Sometimes, due to API retries or frontend issues, the same user accidentally places the same order more than once.




---

ğŸ—‚ï¸ Table: orders

order_id	user_id	product_id	order_date	amount

201	U1	P1	2024-06-01	500
202	U1	P1	2024-06-01	500
203	U1	P2	2024-06-02	800
204	U2	P3	2024-06-03	600
205	U2	P3	2024-06-03	600
206	U3	P4	2024-06-03	900



---

ğŸ¯ Your Task:

> Identify all duplicate orders â€” defined as orders from the same user, for the same product, on the same date, with the same amount.




---

âœ… Expected Output:

user_id	product_id	order_date	amount	duplicate_count

U1	P1	2024-06-01	500	2
U2	P3	2024-06-03	600	2


> We're not showing individual order_ids â€” just the group of duplicates and their count.




---

ğŸš€ Constraints:

Use CTEs to structure the query

Use GROUP BY logic to detect duplicates

You can add HAVING to isolate them



---

ğŸ’¡ Hint (if needed later):

Start with:

SELECT user_id, product_id, order_date, amount, COUNT(*) as duplicate_count
FROM orders
GROUP BY ...
HAVING COUNT(*) > 1

â€”

Ready to attempt it? Or want a tiny nudge next?
Your turn â€” make it shine ğŸ’¥

