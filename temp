from pyspark.sql.functions import col, isnan, when, count
from pyspark.sql.types import NumericType

null_counts = []

for column in df.columns:
    if isinstance(df.schema[column].dataType, NumericType):
        null_expr = count(when(col(column).isNull() | isnan(column), column)).alias(column)
    else:
        null_expr = count(when(col(column).isNull(), column)).alias(column)
    
    null_counts.append(null_expr)

display(df.select(null_counts))
[CAST_INVALID_INPUT] The value 'NW' of the type "STRING" cannot be cast to "DOUBLE" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018



