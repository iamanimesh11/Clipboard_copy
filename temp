from pyspark.sql.functions import sum,col,concat_ws,to_date
from pyspark.sql.window import Window

w=Window.partitionBy("Origin","Flightdate").orderBy("Arrdelay").rowsBetween(Window.unboundedPreceding,0)
df_with_lag=df.withColumn("cumDepDelay",sum("ArrDelay").over(w))
display(df_with_lag.select("origin","Flightdate","ArrDelay","cumDepDelay"))
